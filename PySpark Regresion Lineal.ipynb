{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .appName(\"MLib Regresion Lineal\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.local.dir', '/home/marco/claseBigData/ProyectoBD/tmp'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.id', 'local-1638853246218'),\n",
       " ('spark.driver.memory', '16g'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.driver.host', '192.168.3.5'),\n",
       " ('spark.app.startTime', '1638853245596'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.port', '42709'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MPG,CYLINDERS,DISPLACEMENT,HORSEPOWER,WEIGHT,ACCELERATION,MODELYEAR,NAME',\n",
       " '18,8,307,130,3504,12,70,chevrolet chevelle malibu',\n",
       " '15,8,350,165,3693,11.5,70,buick skylark 320',\n",
       " '18,8,318,150,3436,11,70,plymouth satellite',\n",
       " '16,8,304,150,3433,12,70,amc rebel sst']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoData = sc.textFile(\"clase/auto_miles_per_gallon.csv\")\n",
    "autoData.cache()\n",
    "autoData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18,8,307,130,3504,12,70,chevrolet chevelle malibu',\n",
       " '15,8,350,165,3693,11.5,70,buick skylark 320',\n",
       " '18,8,318,150,3436,11,70,plymouth satellite',\n",
       " '16,8,304,150,3433,12,70,amc rebel sst',\n",
       " '17,8,302,140,3449,10.5,70,ford torino']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLines = autoData.filter(lambda x: \"CYLINDERS\" not in x)\n",
    "dataLines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Usando por defecto la potencia HP promedio\n",
    "avgHP = sc.broadcast(80.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanupData(inputStr):\n",
    "    global avgHP\n",
    "    attList = inputStr.split(\",\")\n",
    "    \n",
    "    hpValue = attList[3]\n",
    "    if hpValue == \"?\":\n",
    "        hpValue = avgHP.value\n",
    "        \n",
    "    values = Row ( MPG = float(attList[0]),\\\n",
    "                 CYLINDERS = float(attList[1]),\\\n",
    "                 DISPLACEMENT = float(attList[2]),\\\n",
    "                 HORSEPOWER = float(hpValue),\\\n",
    "                 WEIGHT = float(attList[4]),\\\n",
    "                 ACCELERATION = float(attList[5]),\\\n",
    "                 MODELYEAR = float(attList[6]),\\\n",
    "                 NAME = attList[7])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MPG=18.0, CYLINDERS=8.0, DISPLACEMENT=307.0, HORSEPOWER=130.0, WEIGHT=3504.0, ACCELERATION=12.0, MODELYEAR=70.0, NAME='chevrolet chevelle malibu'),\n",
       " Row(MPG=15.0, CYLINDERS=8.0, DISPLACEMENT=350.0, HORSEPOWER=165.0, WEIGHT=3693.0, ACCELERATION=11.5, MODELYEAR=70.0, NAME='buick skylark 320'),\n",
       " Row(MPG=18.0, CYLINDERS=8.0, DISPLACEMENT=318.0, HORSEPOWER=150.0, WEIGHT=3436.0, ACCELERATION=11.0, MODELYEAR=70.0, NAME='plymouth satellite'),\n",
       " Row(MPG=16.0, CYLINDERS=8.0, DISPLACEMENT=304.0, HORSEPOWER=150.0, WEIGHT=3433.0, ACCELERATION=12.0, MODELYEAR=70.0, NAME='amc rebel sst')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoMap = dataLines.map(CleanupData)\n",
    "autoMap.cache()\n",
    "autoMap.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[MPG: double, CYLINDERS: double, DISPLACEMENT: double, HORSEPOWER: double, WEIGHT: double, ACCELERATION: double, MODELYEAR: double, NAME: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un dataframe con los datos preprocesados\n",
    "autoDf = spark.createDataFrame(autoMap)\n",
    "autoDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amalisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|              MPG|         CYLINDERS|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|              398|               398|\n",
      "|   mean|23.51457286432161| 5.454773869346734|\n",
      "| stddev|7.815984312565782|1.7010042445332125|\n",
      "|    min|              9.0|               3.0|\n",
      "|    max|             46.6|               8.0|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver analisis descriptivos\n",
    "autoDf.select(\"MPG\",\"CYLINDERS\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to MPG for  MPG 1.0\n",
      "Correlation to MPG for  CYLINDERS -0.7753962854205548\n",
      "Correlation to MPG for  DISPLACEMENT -0.8042028248058979\n",
      "Correlation to MPG for  HORSEPOWER -0.7746308409203807\n",
      "Correlation to MPG for  WEIGHT -0.8317409332443347\n",
      "Correlation to MPG for  ACCELERATION 0.42028891210165004\n",
      "Correlation to MPG for  MODELYEAR 0.5792671330833091\n"
     ]
    }
   ],
   "source": [
    "# Encuentra la correlacion entre los predictores y el objetivo\n",
    "for i in autoDf.columns:\n",
    "    if not (isinstance(autoDf.select(i).take(1)[0][0], str)):\n",
    "        print(\"Correlation to MPG for \",i,autoDf.stat.corr(\"MPG\",i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos para usar MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "def transformToLabeledPoint(row):\n",
    "    lp = (row[\"MPG\"], Vectors.dense([row[\"ACCELERATION\"],\\\n",
    "                                    row[\"DISPLACEMENT\"],\\\n",
    "                                    row[\"WEIGHT\"]]))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|label|           features|\n",
      "+-----+-------------------+\n",
      "| 18.0|[12.0,307.0,3504.0]|\n",
      "| 15.0|[11.5,350.0,3693.0]|\n",
      "| 18.0|[11.0,318.0,3436.0]|\n",
      "| 16.0|[12.0,304.0,3433.0]|\n",
      "| 17.0|[10.5,302.0,3449.0]|\n",
      "| 15.0|[10.0,429.0,4341.0]|\n",
      "| 14.0| [9.0,454.0,4354.0]|\n",
      "| 14.0| [8.5,440.0,4312.0]|\n",
      "| 14.0|[10.0,455.0,4425.0]|\n",
      "| 15.0| [8.5,390.0,3850.0]|\n",
      "| 15.0|[10.0,383.0,3563.0]|\n",
      "| 14.0| [8.0,340.0,3609.0]|\n",
      "| 15.0| [9.5,400.0,3761.0]|\n",
      "| 14.0|[10.0,455.0,3086.0]|\n",
      "| 24.0|[15.0,113.0,2372.0]|\n",
      "| 22.0|[15.5,198.0,2833.0]|\n",
      "| 18.0|[15.5,199.0,2774.0]|\n",
      "| 21.0|[16.0,200.0,2587.0]|\n",
      "| 27.0| [14.5,97.0,2130.0]|\n",
      "| 26.0| [20.5,97.0,1835.0]|\n",
      "+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autoLp = autoMap.map(transformToLabeledPoint)\n",
    "autoDF = spark.createDataFrame(autoLp,[\"label\",\"features\"])\n",
    "autoDF.select(\"label\",\"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar aprendizaje de maquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingData.count():  358\n",
      "testData.count():  40\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = autoDF.randomSplit([0.9,0.1])\n",
    "print(\"trainingData.count(): \",trainingData.count())\n",
    "print(\"testData.count(): \",testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.1302720029022172,-0.012168217951111128,-0.006144290310241698]\n",
      "Intercept: 42.038740767845916\n",
      "+------------------+-----+-------------------+\n",
      "|        prediction|label|           features|\n",
      "+------------------+-----+-------------------+\n",
      "|11.765102415457335| 12.0|[12.5,350.0,4499.0]|\n",
      "| 8.655965361633413| 12.0|[12.5,400.0,4906.0]|\n",
      "|12.159578901699945| 12.0|[13.5,350.0,4456.0]|\n",
      "| 9.573915809820974| 13.0|[12.0,400.0,4746.0]|\n",
      "| 7.153065427585744| 13.0|[12.0,400.0,5140.0]|\n",
      "|11.876941547428828| 13.0|[13.5,350.0,4502.0]|\n",
      "|14.947604206115361| 13.0|[14.0,307.0,4098.0]|\n",
      "|16.788926946201357| 15.0|[10.0,383.0,3563.0]|\n",
      "|18.928174181901305| 16.0|[18.0,258.0,3632.0]|\n",
      "|24.725189563740326| 19.0|[13.0,232.0,2634.0]|\n",
      "| 20.78520552538814| 19.0|[15.0,250.0,3282.0]|\n",
      "| 22.71933311904275| 20.0|[16.5,198.0,3102.0]|\n",
      "| 22.50946421184798| 21.0|[15.0,231.0,3039.0]|\n",
      "|27.922994931216966| 22.0|[16.0,122.0,2395.0]|\n",
      "| 28.04355556701031| 24.0|[15.0,113.0,2372.0]|\n",
      "| 30.01065322324078| 24.0| [15.5,90.0,2108.0]|\n",
      "|28.686254857624135| 24.0|[15.5,113.0,2278.0]|\n",
      "| 28.05279114232238| 26.0|[15.5,108.0,2391.0]|\n",
      "| 29.29669521041124| 26.0| [17.7,98.0,2255.0]|\n",
      "|14.721632990787771| 15.5|[14.3,351.0,4054.0]|\n",
      "+------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construir el modelo sobre los datos de entrenamiento\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(maxIter=10)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# Muestra de metricas\n",
    "print(\"Coefficients: \"+str(lrModel.coefficients))\n",
    "print(\"Intercept: \"+str(lrModel.intercept))\n",
    "\n",
    "# Predict sobre los datos de test\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.select(\"prediction\",\"label\",\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023822815469987"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regresion lineal e indicador R2\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\",\\\n",
    "                               labelCol=\"label\", metricName=\"r2\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marco/anaconda3/bin/python\n",
      "3.8.3 (default, Jul  2 2020, 16:21:59) \n",
      "[GCC 7.3.0]\n",
      "sys.version_info(major=3, minor=8, micro=3, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
