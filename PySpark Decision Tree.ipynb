{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .appName(\"MLib Decision Tree\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.id', 'local-1638856180271'),\n",
       " ('spark.local.dir', '/home/marco/claseBigData/ProyectoBD/tmp'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.memory', '16g'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.driver.host', '192.168.3.5'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.port', '35803'),\n",
       " ('spark.app.startTime', '1638856179666'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.1,3.5,1.4,0.2,setosa',\n",
       " '4.9,3,1.4,0.2,setosa',\n",
       " '4.7,3.2,1.3,0.2,setosa',\n",
       " '4.6,3.1,1.5,0.2,setosa',\n",
       " '5,3.6,1.4,0.2,setosa']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisData = sc.textFile(\"clase/iris.csv\")\n",
    "irisData.cache()\n",
    "irisData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.1,3.5,1.4,0.2,setosa',\n",
       " '4.9,3,1.4,0.2,setosa',\n",
       " '4.7,3.2,1.3,0.2,setosa',\n",
       " '4.6,3.1,1.5,0.2,setosa',\n",
       " '5,3.6,1.4,0.2,setosa']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Archivo no contiene encabezados\n",
    "irisData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[SEPAL_LENGTH: double, SEPAL_WIDTH: double, PETAL_LENGTH: double, PETAL_WIDTH: double, SPECIES: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Crea DataFrame a partir de los datos\n",
    "parts = irisData.map(lambda l: l.split(\",\"))\n",
    "irisMap = parts.map(lambda p: Row(SEPAL_LENGTH=float(p[0]),\\\n",
    "                                 SEPAL_WIDTH=float(p[1]),\\\n",
    "                                 PETAL_LENGTH=float(p[2]),\\\n",
    "                                 PETAL_WIDTH=float(p[3]),\\\n",
    "                                 SPECIES=p[4]))\n",
    "\n",
    "# Infiere el esquema y registra el dataframe como tabla\n",
    "irisDf = spark.createDataFrame(irisMap)\n",
    "irisDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|SEPAL_LENGTH|SEPAL_WIDTH|PETAL_LENGTH|PETAL_WIDTH|SPECIES|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SPECIES='setosa', IND_SPECIES=0.0),\n",
       " Row(SPECIES='virginica', IND_SPECIES=2.0),\n",
       " Row(SPECIES='versicolor', IND_SPECIES=1.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos un indexador numerico para la etiqueta / columna de destino\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"SPECIES\",outputCol=\"IND_SPECIES\")\n",
    "si_model = stringIndexer.fit(irisDf)\n",
    "irisNormDf = si_model.transform(irisDf)\n",
    "\n",
    "irisNormDf.select(\"SPECIES\",\"IND_SPECIES\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[SEPAL_LENGTH: double, SEPAL_WIDTH: double, PETAL_LENGTH: double, PETAL_WIDTH: double, SPECIES: string, IND_SPECIES: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisNormDf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-----------------+------------------+---------+------------------+\n",
      "|summary|      SEPAL_LENGTH|        SEPAL_WIDTH|     PETAL_LENGTH|       PETAL_WIDTH|  SPECIES|       IND_SPECIES|\n",
      "+-------+------------------+-------------------+-----------------+------------------+---------+------------------+\n",
      "|  count|               150|                150|              150|               150|      150|               150|\n",
      "|   mean| 5.843333333333332| 3.0573333333333337|3.758000000000001|1.1993333333333331|     null|               1.0|\n",
      "| stddev|0.8280661279778633|0.43586628493669777|1.765298233259466|0.7622376689603467|     null|0.8192319205190407|\n",
      "|    min|               4.3|                2.0|              1.0|               0.1|   setosa|               0.0|\n",
      "|    max|               7.9|                4.4|              6.9|               2.5|virginica|               2.0|\n",
      "+-------+------------------+-------------------+-----------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisNormDf.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El siguiente paso no se deberia realizar ya que estariamos tomando correlacion de numericas vs categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to SPECIES for  SEPAL_LENGTH 0.7825612318100816\n",
      "Correlation to SPECIES for  SEPAL_WIDTH -0.4266575607811234\n",
      "Correlation to SPECIES for  PETAL_LENGTH 0.9490346990083889\n",
      "Correlation to SPECIES for  PETAL_WIDTH 0.9565473328764028\n",
      "Correlation to SPECIES for  IND_SPECIES 1.0\n"
     ]
    }
   ],
   "source": [
    "# Encuentra la correlacion entre los predictores y el objetivo\n",
    "for i in irisNormDf.columns:\n",
    "    if not (isinstance(irisNormDf.select(i).take(1)[0][0], str)):\n",
    "        print(\"Correlation to SPECIES for \",i,irisNormDf.stat.corr(\"IND_SPECIES\",i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos para usar MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "def transformToLabeledPoint(row):\n",
    "    lp = (row[\"SPECIES\"], row[\"IND_SPECIES\"], Vectors.dense([row[\"SEPAL_LENGTH\"],\\\n",
    "                                                             row[\"SEPAL_WIDTH\"],\\\n",
    "                                                             row[\"PETAL_LENGTH\"],\\\n",
    "                                                             row[\"PETAL_WIDTH\"]]))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------------+\n",
      "|species|label|         features|\n",
      "+-------+-----+-----------------+\n",
      "| setosa|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "| setosa|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "| setosa|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "| setosa|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "| setosa|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "| setosa|  0.0|[5.4,3.9,1.7,0.4]|\n",
      "| setosa|  0.0|[4.6,3.4,1.4,0.3]|\n",
      "| setosa|  0.0|[5.0,3.4,1.5,0.2]|\n",
      "| setosa|  0.0|[4.4,2.9,1.4,0.2]|\n",
      "| setosa|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "+-------+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[species: string, label: double, features: vector]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisLp = irisNormDf.rdd.map(transformToLabeledPoint)\n",
    "irisLpDf = spark.createDataFrame(irisLp,[\"species\",\"label\",\"features\"])\n",
    "irisLpDf.select(\"species\",\"label\",\"features\").show(10)\n",
    "irisLpDf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar aprendizaje de maquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingData.count():  127\n",
      "testData.count():  23\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = irisLpDf.randomSplit([0.8,0.2])\n",
    "print(\"trainingData.count(): \",trainingData.count())\n",
    "print(\"testData.count(): \",testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(species='setosa', label=0.0, features=DenseVector([4.3, 3.0, 1.1, 0.1])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([4.5, 2.3, 1.3, 0.3])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([4.6, 3.2, 1.4, 0.2])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([4.6, 3.6, 1.0, 0.2])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([4.9, 3.6, 1.4, 0.1])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([5.0, 3.3, 1.4, 0.2])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([5.1, 3.5, 1.4, 0.3])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([5.1, 3.8, 1.5, 0.3])),\n",
       " Row(species='setosa', label=0.0, features=DenseVector([5.4, 3.9, 1.7, 0.4])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([4.9, 2.4, 3.3, 1.0])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([5.9, 3.0, 4.2, 1.5])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([5.9, 3.2, 4.8, 1.8])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([6.7, 3.1, 4.4, 1.4])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([5.8, 2.6, 4.0, 1.2])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([6.0, 2.7, 5.1, 1.6])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([6.1, 3.0, 4.6, 1.4])),\n",
       " Row(species='versicolor', label=1.0, features=DenseVector([6.7, 3.1, 4.7, 1.5])),\n",
       " Row(species='virginica', label=2.0, features=DenseVector([6.3, 3.3, 6.0, 2.5])),\n",
       " Row(species='virginica', label=2.0, features=DenseVector([6.3, 3.4, 5.6, 2.4])),\n",
       " Row(species='virginica', label=2.0, features=DenseVector([6.8, 3.0, 5.5, 2.1])),\n",
       " Row(species='virginica', label=2.0, features=DenseVector([7.6, 3.0, 6.6, 2.1])),\n",
       " Row(species='virginica', label=2.0, features=DenseVector([7.7, 2.6, 6.9, 2.3])),\n",
       " Row(species='virginica', label=2.0, features=DenseVector([7.7, 2.8, 6.7, 2.0]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de Nodos:  5\n",
      "Profundidad:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=0.0, species='setosa', label=0.0),\n",
       " Row(prediction=1.0, species='versicolor', label=1.0),\n",
       " Row(prediction=1.0, species='versicolor', label=1.0),\n",
       " Row(prediction=2.0, species='versicolor', label=1.0),\n",
       " Row(prediction=1.0, species='versicolor', label=1.0),\n",
       " Row(prediction=1.0, species='versicolor', label=1.0),\n",
       " Row(prediction=1.0, species='versicolor', label=1.0),\n",
       " Row(prediction=1.0, species='versicolor', label=1.0),\n",
       " Row(prediction=1.0, species='versicolor', label=1.0),\n",
       " Row(prediction=2.0, species='virginica', label=2.0),\n",
       " Row(prediction=2.0, species='virginica', label=2.0),\n",
       " Row(prediction=2.0, species='virginica', label=2.0),\n",
       " Row(prediction=2.0, species='virginica', label=2.0),\n",
       " Row(prediction=2.0, species='virginica', label=2.0),\n",
       " Row(prediction=2.0, species='virginica', label=2.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construir el modelo sobre los datos de entrenamiento\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Crear el modelo\n",
    "dtClassifier = DecisionTreeClassifier(maxDepth=2, labelCol=\"label\",featuresCol=\"features\")\n",
    "dtModel = dtClassifier.fit(trainingData)\n",
    "\n",
    "# Muestra de metricas\n",
    "print(\"Nro de Nodos: \",dtModel.numNodes)\n",
    "print(\"Profundidad: \",dtModel.depth)\n",
    "\n",
    "\n",
    "# Predict sobre los datos de test\n",
    "predictions = dtModel.transform(testData)\n",
    "predictions.select(\"prediction\",\"species\",\"label\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluar Accuracy\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\\\n",
    "                               labelCol=\"label\", metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|    7|\n",
      "|  2.0|       2.0|    6|\n",
      "|  1.0|       2.0|    1|\n",
      "|  0.0|       0.0|    9|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marco/anaconda3/bin/python\n",
      "3.8.3 (default, Jul  2 2020, 16:21:59) \n",
      "[GCC 7.3.0]\n",
      "sys.version_info(major=3, minor=8, micro=3, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
