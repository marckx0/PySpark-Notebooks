{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .appName(\"MLib Naive Bayes\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.local.dir', '/home/marco/claseBigData/ProyectoBD/tmp'),\n",
       " ('spark.app.id', 'local-1638919110372'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.memory', '16g'),\n",
       " ('spark.app.startTime', '1638919109753'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.driver.host', '192.168.3.5'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.driver.port', '33787'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham,Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...,,,,,,,,,',\n",
       " 'ham,Ok lar... Joking wif u oni...,,,,,,,,,,',\n",
       " 'ham,U dun say so early hor... U c already then say...,,,,,,,,,,',\n",
       " \"ham,Nah I don't think he goes to usf, he lives around here though,,,,,,,,,\",\n",
       " 'ham,Even my brother is not like to speak with me. They treat me like aids patent.,,,,,,,,,,',\n",
       " \"ham,As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune,,,,,,,,,,\",\n",
       " \"ham,I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.,,,,,,,,,\",\n",
       " \"ham,I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.,,,,,,,,,,\",\n",
       " 'ham,I HAVE A DATE ON SUNDAY WITH WILL!!,,,,,,,,,,',\n",
       " \"ham,Oh k...i'm watching here:),,,,,,,,,,\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smsData = sc.textFile(\"clase/SMSSpamCollection.csv\")\n",
    "smsData.cache()\n",
    "smsData.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar Datos para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|Go until jurong p...|\n",
      "|  0.0|Ok lar... Joking ...|\n",
      "|  0.0|U dun say so earl...|\n",
      "|  0.0|Nah I don't think...|\n",
      "|  0.0|Even my brother i...|\n",
      "|  0.0|As per your reque...|\n",
      "|  0.0|I'm gonna be home...|\n",
      "|  0.0|I've been searchi...|\n",
      "|  0.0|I HAVE A DATE ON ...|\n",
      "|  0.0|Oh k...i'm watchi...|\n",
      "|  0.0|Eh u remember how...|\n",
      "|  0.0|Fine if thats th...|\n",
      "|  0.0|Is that seriously...|\n",
      "|  0.0|I‘m going to try ...|\n",
      "|  0.0|So ü pay first la...|\n",
      "|  0.0|Aft i finish my l...|\n",
      "|  0.0|Ffffffffff. Alrig...|\n",
      "|  0.0|Just forced mysel...|\n",
      "|  0.0|Lol your always s...|\n",
      "|  0.0|Did you catch the...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def TransformToVector(inputStr):\n",
    "    attList = inputStr.split(\",\")\n",
    "    smsType = 0.0 if attList[0] == \"ham\" else 1.0\n",
    "    return [smsType, attList[1]]\n",
    "\n",
    "smsXformed = smsData.map(TransformToVector)\n",
    "\n",
    "smsDf = spark.createDataFrame(smsXformed, [\"label\",\"message\"])\n",
    "\n",
    "smsDf.cache()\n",
    "smsDf.select(\"label\",\"message\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividiendo datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingData.count():  900\n",
      "testData.count():  100\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = smsDf.randomSplit([0.9,0.1])\n",
    "print(\"trainingData.count(): \",trainingData.count())\n",
    "print(\"testData.count(): \",testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup pipeline\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, IDF\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Dividir en palabras y luego construir TF-IDF\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(),\\\n",
    "                     outputCol=\"tempfeatures\")\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "nbClassifier = NaiveBayes()\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nbClassifier])\n",
    "\n",
    "# Construir un modelo con una tuberia\n",
    "nbModel = pipeline.fit(trainingData)\n",
    "# Predict sobre datos de prueba\n",
    "prediction = nbModel.transform(testData)\n",
    "\n",
    "# Evaluar la precision\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\\\n",
    "                                              labelCol=\"label\", metricName=\"accuracy\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0|   45|\n",
      "|  0.0|       1.0|    3|\n",
      "|  1.0|       0.0|    4|\n",
      "|  0.0|       0.0|   48|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.groupBy(\"label\",\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marco/anaconda3/bin/python\n",
      "3.8.3 (default, Jul  2 2020, 16:21:59) \n",
      "[GCC 7.3.0]\n",
      "sys.version_info(major=3, minor=8, micro=3, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
